{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b912cbae",
   "metadata": {},
   "source": [
    "## KデータとBデータを結合しCSV保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728159ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from string import ascii_letters\n",
    "from string import digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36694d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ディレクトリのファイルリストを取得\n",
    "files_K = glob.glob(\"K/*\")\n",
    "files_B = glob.glob(\"B/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a379ec8",
   "metadata": {},
   "source": [
    "### Bデータ取り込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75dc55bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#開催地、レース番号、日付(すべてstr型)を元ににレースIDを追加\u001b[39;00m\n\u001b[1;32m     68\u001b[0m df_B[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mレースID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_B[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m日付\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m df_B[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m開催地\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m df_B[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mレース番号\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 70\u001b[0m df_all_B \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_all_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_B\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/internals/concat.py:177\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    167\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ea_compat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Bデータを全て取り込み結合する\n",
    "df_all_B = pd.DataFrame()\n",
    "\n",
    "for file in files_B:\n",
    "\n",
    "  #データ読み込み\n",
    "  with open(file, encoding='shift-jis') as f:\n",
    "    data1 = f.readlines()\n",
    "\n",
    "  #レース日付読み込み\n",
    "  date = os.path.basename(file)\n",
    "  date = re.sub(r\"\\D\", \"\", date)\n",
    "\n",
    "  #余分なスペース、改行を消去\n",
    "  data2 = [s.replace('\\u3000', '').replace('\\n', '') for s in data1]\n",
    "\n",
    "  #全角文字を半角文字に変換\n",
    "  han = ascii_letters + digits\n",
    "  table = {c + 65248: c for c in map(ord, han)}\n",
    "  data3 = [name.translate(table) for name in data2]\n",
    "\n",
    "  #必要データ抽出\n",
    "  data4 = [row for row in data3 if re.match('^[0-9]', row)]\n",
    "\n",
    "  #行検索用\n",
    "  pattern_place1 = '\\d{2}[B][B]'\n",
    "  pattern_race_num1 = '\\d+[R]'\n",
    "  pattern_racer1 = '^[1-6]\\s\\d{4}'\n",
    "  pattern_place_re1 = re.compile(pattern_place1)\n",
    "  pattern_race_num_re1 = re.compile(pattern_race_num1)\n",
    "  pattern_racer_re1 = re.compile(pattern_racer1)\n",
    "\n",
    "\n",
    "  #データ取得用\n",
    "  pattern_place2 = '(\\d{2})[B][B]'\n",
    "  pattern_race_num2 = '(\\d+)[R]'\n",
    "  pattern_racer2 = '^([1-6])\\s(\\d{4})([^0-9]+)(\\d{2})([^0-9]+)(\\d{2})([AB]\\d{1})\\s(\\d.\\d{2})\\s*(\\d+.\\d{2})\\s*(\\d+.\\d{2})\\s*(\\d+.\\d{2})\\s*(\\d+)\\s*(\\d+.\\d{2})\\s*(\\d+)\\s*(\\d+.\\d{2})'\n",
    "  pattern_place_re2 = re.compile(pattern_place2)\n",
    "  pattern_race_num_re2 = re.compile(pattern_race_num2)\n",
    "  pattern_racer_re2 = re.compile(pattern_racer2)\n",
    "\n",
    "  #必要データ取得\n",
    "  values = []\n",
    "  for row in data4:\n",
    "    if re.match(pattern_place_re1, row):\n",
    "      place = re.match(pattern_place_re2, row).groups()\n",
    "      place_elm = place[0]\n",
    "\n",
    "    elif re.match(pattern_race_num_re1, row):\n",
    "      race_num = re.match(pattern_race_num_re2, row).groups()\n",
    "      race_num_elm = race_num[0].zfill(2)\n",
    "\n",
    "    elif re.match(pattern_racer_re1, row):\n",
    "      value = re.match(pattern_racer_re2, row).groups()\n",
    "      val_li = []\n",
    "      for i in value:\n",
    "        val_li.append(i)\n",
    "      val_li.append(place_elm)\n",
    "      val_li.append(race_num_elm)\n",
    "      val_li.append(date)\n",
    "      values.append(val_li)\n",
    "\n",
    "  #データフレーム作成\n",
    "  column = ['艇番', '選手登番', '選手名', '年齢', '支部', '体重', '級別', '全国勝率', '全国2連率', '当地勝率', '当地2連率', 'モーターNO', 'モーター2連率', 'ボートNO', 'ボート2連率', '開催地', 'レース番号', '日付']\n",
    "  df_B = pd.DataFrame(values, columns=column)\n",
    "\n",
    "  #開催地、レース番号、日付(すべてstr型)を元ににレースIDを追加\n",
    "  df_B['レースID'] = df_B['日付'] + df_B['開催地'] + df_B['レース番号']\n",
    "\n",
    "  df_all_B = pd.concat([df_all_B, df_B])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c524926",
   "metadata": {},
   "source": [
    "### Kデータ取り込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee7aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kデータを全て取り込み結合する\n",
    "df_all_K = pd.DataFrame()\n",
    "\n",
    "for file in files_K:\n",
    "\n",
    "  #データ読み込み\n",
    "  with open(file, encoding='shift-jis') as f:\n",
    "    data5 = f.readlines()\n",
    "\n",
    "  #レース日付読み込み\n",
    "  date = os.path.basename(file)\n",
    "  date = re.sub(r\"\\D\", \"\", date)\n",
    "\n",
    "  #余分なスペース、改行を消去\n",
    "  data6 = [s.replace('\\u3000', '').replace('\\n', '') for s in data5]\n",
    "\n",
    "  #全角文字を半角文字に変換\n",
    "  han = ascii_letters + digits\n",
    "  table = {c + 65248: c for c in map(ord, han)}\n",
    "  data7 = [name.translate(table) for name in data6]\n",
    "\n",
    "  #必要データ抽出\n",
    "  data8 = [row for row in data7 if re.match('[0-9]', row) or re.match('\\s\\s[0-9]', row) or re.match('\\s\\s\\s[0-9]', row)]\n",
    "\n",
    "\n",
    "  #行検索用\n",
    "  pattern_place1 = '\\d{2}[K][B]'\n",
    "  pattern_race_num1 = '\\s+\\d+[R]'\n",
    "  pattern_racer1 = '\\s+\\d+\\s+[1-6]\\s\\d{4}\\s.*?\\d+\\.\\d+\\s.*?\\d+\\.\\d+' #カラム追加時はここを修正する\n",
    "  pattern_place_re1 = re.compile(pattern_place1)\n",
    "  pattern_race_num_re1 = re.compile(pattern_race_num1)\n",
    "  pattern_racer_re1 = re.compile(pattern_racer1)\n",
    "\n",
    "  #データ取得用\n",
    "  pattern_place2 = '(\\d{2})[K][B]'\n",
    "  pattern_race_num2 = '\\s+(\\d+)[R]'\n",
    "  pattern_racer2 = '\\s+(\\d+)\\s+[1-6]\\s(\\d{4})\\s.*?(\\d+\\.\\d+)\\s.*?(\\d+\\.\\d+)' #カラム追加時はここを修正する\n",
    "  pattern_place_re2 = re.compile(pattern_place2)\n",
    "  pattern_race_num_re2 = re.compile(pattern_race_num2)\n",
    "  pattern_racer_re2 = re.compile(pattern_racer2)\n",
    "\n",
    "\n",
    "  #必要データ取得\n",
    "  values = []\n",
    "  for row in data8:\n",
    "    if re.match(pattern_place_re1, row):\n",
    "      place = re.match(pattern_place_re2, row).groups()\n",
    "      place_elm = place[0]\n",
    "\n",
    "    elif re.match(pattern_race_num_re1, row):\n",
    "      race_num = re.match(pattern_race_num_re2, row).groups()\n",
    "      race_num_elm = race_num[0].zfill(2)\n",
    "\n",
    "    elif re.match(pattern_racer_re1, row):\n",
    "      value = re.match(pattern_racer_re2, row).groups()\n",
    "      val_li = []\n",
    "      for i in value:\n",
    "        val_li.append(i)\n",
    "      val_li.append(place_elm)\n",
    "      val_li.append(race_num_elm)\n",
    "      val_li.append(date)\n",
    "      values.append(val_li)\n",
    "\n",
    "  #データフレーム作成\n",
    "  column = ['実着順', '選手登番', '展示','ｽﾀｰﾄﾀｲﾐﾝｸ', '開催地', 'レース番号', '日付'] #'展示タイム','ｽﾀｰﾄﾀｲﾐﾝｸ','レースタイム'\n",
    "  df_K = pd.DataFrame(values, columns=column)\n",
    "\n",
    "  #開催地、レース番号、日付(すべてstr型)を元ににレースIDを追加\n",
    "  df_K['レースID'] = df_K['日付'] + df_K['開催地'] + df_K['レース番号']\n",
    "  df_K = df_K[['実着順', '選手登番','展示','ｽﾀｰﾄﾀｲﾐﾝｸ','レースID']] # '展示タイム','ｽﾀｰﾄﾀｲﾐﾝｸ','レースタイム'\n",
    "\n",
    "  df_all_K = pd.concat([df_all_K, df_K])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c5014",
   "metadata": {},
   "source": [
    "### KとBデータを結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e61151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#レース予定Bとレース結果Kデータ結合\n",
    "df = df_all_K.merge(df_all_B, how='left', on=['レースID', '選手登番'])\n",
    "\n",
    "# マージ前に選手登番を整数に変換\n",
    "df['選手登番'] = df['選手登番'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1a9e3",
   "metadata": {},
   "source": [
    "### 結合したデータを一時保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a332c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一時保存\n",
    "\n",
    "#保存するフォルダのパスを指定します\n",
    "folder_path = 'DataFrame_csv'\n",
    "\n",
    "# ファイルのパスをフォルダパスと結合してCSVファイルを保存します\n",
    "file_path = os.path.join(folder_path, 'K_B_Data_20200501-20241031.csv')\n",
    "df.to_csv(file_path, index=False, encoding='shift-jis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb82162",
   "metadata": {},
   "source": [
    "## Kデータからレース結果詳細をcsv保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a2483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作業を開始します\n",
      "results_csv_detail/results_20200501-20241031.csv を作成しました\n",
      "作業を終了しました\n"
     ]
    }
   ],
   "source": [
    "# 解凍したテキストファイルの格納先を指定\n",
    "TEXT_FILE_DIR = \"/home/jovyan/work/train_data/K/\"\n",
    "\n",
    "# CSVファイルの保存先を指定\n",
    "CSV_FILE_DIR = \"results_csv_detail/\"\n",
    "\n",
    "# CSVファイルの名前を指定　※YYYYMMDDには対象期間を入力\n",
    "CSV_FILE_NAME = \"results_20200501-20241031.csv\"\n",
    "\n",
    "# CSVファイルのヘッダーを指定\n",
    "CSV_FILE_HEADER = \"レースID,タイトル,日次,レース日,レース場,\\\n",
    "レース回,レース名,距離(m),天候,風向,風速(m),波の高さ(cm),決まり手,\\\n",
    "単勝_艇番,単勝_払戻金,複勝_1着_艇番,複勝_1着_払戻金,複勝_2着_艇番,複勝_2着_払戻金,\\\n",
    "2連単_組番,2連単_払戻金,2連単_人気,2連複_組番,2連複_払戻金,2連複_人気,\\\n",
    "拡連複_1-2着_組番,拡連複_1-2着_払戻金,拡連複_1-2着_人気,\\\n",
    "拡連複_1-3着_組番,拡連複_1-3着_払戻金,拡連複_1-3着_人気,\\\n",
    "拡連複_2-3着_組番,拡連複_2-3着_払戻金,拡連複_2-3着_人気,\\\n",
    "3連単_組番,3連単_払戻金,3連単_人気,3連複_組番,3連複_払戻金,3連複_人気,\\\n",
    "1着_着順,1着_艇番,1着_登録番号,1着_選手名,1着_モーター番号,1着_ボート番号,\\\n",
    "1着_展示タイム,1着_進入コース,1着_スタートタイミング,1着_レースタイム,\\\n",
    "2着_着順,2着_艇番,2着_登録番号,2着_選手名,2着_モーター番号,2着_ボート番号,\\\n",
    "2着_展示タイム,2着_進入コース,2着_スタートタイミング,2着_レースタイム,\\\n",
    "3着_着順,3着_艇番,3着_登録番号,3着_選手名,3着_モーター番号,3着_ボート番号,\\\n",
    "3着_展示タイム,3着_進入コース,3着_スタートタイミング,3着_レースタイム,\\\n",
    "4着_着順,4着_艇番,4着_登録番号,4着_選手名,4着_モーター番号,4着_ボート番号,\\\n",
    "4着_展示タイム,4着_進入コース,4着_スタートタイミング,4着_レースタイム,\\\n",
    "5着_着順,5着_艇番,5着_登録番号,5着_選手名,5着_モーター番号,5着_ボート番号,\\\n",
    "5着_展示タイム,5着_進入コース,5着_スタートタイミング,5着_レースタイム,\\\n",
    "6着_着順,6着_艇番,6着_登録番号,6着_選手名,6着_モーター番号,6着_ボート番号,\\\n",
    "6着_展示タイム,6着_進入コース,6着_スタートタイミング,6着_レースタイム,\\n\"\n",
    "\n",
    "\n",
    "# テキストファイルからデータを抽出し、CSVファイルに書き込む関数 get_data を定義\n",
    "def get_data(text_file):\n",
    "    # CSVファイルを追記モードで開く\n",
    "    csv_file = open(CSV_FILE_DIR + CSV_FILE_NAME, \"a\", encoding=\"shift_jis\")\n",
    "\n",
    "    # テキストファイルから中身を順に取り出す\n",
    "    for line in text_file:\n",
    "\n",
    "        # キーワード「競争成績」を見つけたら(rは正規表現でraw文字列を指定するおまじない)\n",
    "        if re.search(r\"競走成績\", line):\n",
    "            # 1行スキップ\n",
    "            text_file.readline()\n",
    "\n",
    "            # タイトルを格納\n",
    "            line = text_file.readline()\n",
    "            title = line[:-1].strip()\n",
    "\n",
    "            # 1行スキップ\n",
    "            text_file.readline()\n",
    "\n",
    "            # 日次・レース日・レース場を格納\n",
    "            line = text_file.readline()\n",
    "            day = line[3:7].replace(' ', '')\n",
    "            date = line[17:27].replace(' ', '0')\n",
    "            stadium = line[62:65].replace('　', '')\n",
    "\n",
    "        # レース回の「R」と距離の「H」を同じ行に見つけたら -> これ以降に競走成績の詳細が記載\n",
    "        if re.search(r\"R\", line) and re.search(r\"H\", line):\n",
    "\n",
    "            # レース名にキーワード「進入固定」が割り込んだ際の補正(「進入固定戦隊」は除くためＨまで含めて置換)\n",
    "            if re.search(r\"進入固定\", line):\n",
    "                line = line.replace('進入固定       H', '進入固定           H')\n",
    "\n",
    "            # レース回、レース名、距離(m)、天候、風向、風速(m)、波の高さ(cm)を取得\n",
    "            race_round = line[2:5].replace(' ', '0')\n",
    "            race_name = line[12:31].replace('　', '')\n",
    "            distance = line[36:40]\n",
    "            weather = line[43:45].strip()\n",
    "            wind_direction = line[50:52].strip()\n",
    "            wind_velocity = line[53:55].strip()\n",
    "            wave_height = line[60:63].strip()\n",
    "\n",
    "            # 決まり手を取得\n",
    "            line = text_file.readline()\n",
    "            winning_technique = line[50:55].strip()\n",
    "\n",
    "            # 1行スキップ\n",
    "            text_file.readline()\n",
    "\n",
    "            # 選手データを格納する変数を定義\n",
    "            result_racer = \"\"\n",
    "\n",
    "            # 選手データを取り出す行(開始行)を格納\n",
    "            line = text_file.readline()\n",
    "\n",
    "            # 空行まで処理を繰り返す = 1～6艇分の選手データを取得\n",
    "            while line != \"\\n\":\n",
    "                # 選手データを格納(行末にカンマが入らないように先頭にカンマを入れる)\n",
    "                result_racer += \",\" + line[2:4] + \",\" + line[6] + \",\" + line[8:12] \\\n",
    "                                + \",\" + line[13:21] + \",\" + line[22:24] + \",\" + line[27:29] \\\n",
    "                                + \",\" + line[30:35].strip() + \",\" + line[38] + \",\" + line[43:47] \\\n",
    "                                + \",\" + line[52:58]\n",
    "\n",
    "                # 次の行を読み込む\n",
    "                line = text_file.readline()\n",
    "\n",
    "            # レース結果を取り出す行(開始行)を格納\n",
    "            line = text_file.readline()\n",
    "\n",
    "            # 空行まで処理を繰り返す = レース結果を取得\n",
    "            while line != \"\\n\":\n",
    "\n",
    "                # 単勝の結果を取得\n",
    "                if re.search(r\"単勝\", line):\n",
    "\n",
    "                    # 文字列「特払い」が割り込んだ際の補正\n",
    "                    if re.search(r\"特払い\", line):\n",
    "                        line = line.replace('        特払い   ', '   特払い        ')\n",
    "\n",
    "                    result_win = line[15] + \",\" + line[22:29].strip()\n",
    "\n",
    "                # 複勝の結果を取得\n",
    "                if re.search(r\"複勝\", line):\n",
    "\n",
    "                    # 文字列「特払い」が割り込んだ際の補正\n",
    "                    if re.search(r\"特払い\", line):\n",
    "                        line = line.replace('        特払い   ', '   特払い        ')\n",
    "\n",
    "                    # 複勝_2着のデータが存在しない場合の分岐\n",
    "                    if len(line) <= 33:\n",
    "                        result_place_show = line[15] + \",\" + line[22:29].strip() \\\n",
    "                                            + \",\" + \",\"\n",
    "                    else:\n",
    "                        result_place_show = line[15] + \",\" + line[22:29].strip() \\\n",
    "                                            + \",\" + line[31] + \",\" + line[38:45].strip()\n",
    "\n",
    "                # 2連単の結果を取得\n",
    "                if re.search(r\"２連単\", line):\n",
    "                    result_exacta = line[14:17] + \",\" + line[21:28].strip() \\\n",
    "                                    + \",\" + line[36:38].strip()\n",
    "\n",
    "                # 2連複の結果を取得\n",
    "                if re.search(r\"２連複\", line):\n",
    "                    result_quinella = line[14:17] + \",\" + line[21:28].strip() \\\n",
    "                                      + \",\" + line[36:38].strip()\n",
    "\n",
    "                # 拡連複の結果を取得\n",
    "                if re.search(r\"拡連複\", line):\n",
    "                    # 1-2着\n",
    "                    result_quinella_place = line[14:17] + \",\" + line[21:28].strip() \\\n",
    "                                            + \",\" + line[36:38].strip()\n",
    "\n",
    "                    # 1-3着\n",
    "                    line = text_file.readline()\n",
    "                    result_quinella_place += \",\" + line[17:20] + \",\" + line[24:31].strip() \\\n",
    "                                             + \",\" + line[39:41].strip()\n",
    "\n",
    "                    # 2-3着\n",
    "                    line = text_file.readline()\n",
    "                    result_quinella_place += \",\" + line[17:20] + \",\" + line[24:31].strip() \\\n",
    "                                             + \",\" + line[39:41].strip()\n",
    "\n",
    "                # 3連単の結果を取得\n",
    "                if re.search(r\"３連単\", line):\n",
    "                    result_trifecta = line[14:19] + \",\" + line[21:28].strip() \\\n",
    "                                      + \",\" + line[35:38].strip()\n",
    "\n",
    "                # 3連複の結果を取得\n",
    "                if re.search(r\"３連複\", line):\n",
    "                    result_trio = line[14:19] + \",\" + line[21:28].strip() \\\n",
    "                                  + \",\" + line[35:38].strip()\n",
    "\n",
    "                # 次の行を読み込む\n",
    "                line = text_file.readline()\n",
    "\n",
    "            # レースコードを生成\n",
    "            dict_stadium = {'桐生': '01', '戸田': '02', '江戸川': '03', '平和島': '04',\n",
    "                            '多摩川': '05', '浜名湖': '06', '蒲郡': '07', '常滑': '08',\n",
    "                            '津': '09', '三国': '10', '琵琶湖': '11','びわこ': '11', '住之江': '12',\n",
    "                            '尼崎': '13', '鳴門': '14', '丸亀': '15', '児島': '16',\n",
    "                            '宮島': '17', '徳山': '18', '下関': '19', '若松': '20',\n",
    "                            '芦屋': '21', '福岡': '22', '唐津': '23', '大村': '24'\n",
    "                            }\n",
    "\n",
    "            race_code = date[2:4] + date[5:7] + date[8:10] + dict_stadium[stadium] + race_round[0:2]\n",
    "\n",
    "            # 抽出したデータをCSVファイルに書き込む\n",
    "            csv_file.write(race_code + \",\" + title + \",\" + day + \",\" + date + \",\" + stadium \\\n",
    "                           + \",\" + race_round + \",\" + race_name + \",\" + distance + \",\" + weather \\\n",
    "                           + \",\" + wind_direction + \",\" + wind_velocity + \",\" + wave_height \\\n",
    "                           + \",\" + winning_technique + \",\" + result_win + \",\" + result_place_show \\\n",
    "                           + \",\" + result_exacta + \",\" + result_quinella + \",\" + result_quinella_place \\\n",
    "                           + \",\" + result_trifecta + \",\" + result_trio + result_racer + \"\\n\")\n",
    "\n",
    "    # CSVファイルを閉じる\n",
    "    csv_file.close()\n",
    "\n",
    "\n",
    "# 開始合図\n",
    "print(\"作業を開始します\")\n",
    "\n",
    "# CSVファイルを格納するフォルダを作成\n",
    "os.makedirs(CSV_FILE_DIR, exist_ok=True)\n",
    "\n",
    "# CSVファイルを作成しヘッダ情報を書き込む\n",
    "csv_file = open(CSV_FILE_DIR + CSV_FILE_NAME, \"w\", encoding=\"shift_jis\")\n",
    "csv_file.write(CSV_FILE_HEADER)\n",
    "csv_file.close()\n",
    "\n",
    "# テキストファイルのリストを取得\n",
    "text_file_list = os.listdir(TEXT_FILE_DIR)\n",
    "\n",
    "# リストからファイル名を順に取り出す\n",
    "for text_file_name in text_file_list:\n",
    "\n",
    "    # 拡張子が TXT のファイルに対してのみ実行\n",
    "    if re.search(\".TXT\", text_file_name):\n",
    "        # テキストファイルを開く\n",
    "        text_file = open(TEXT_FILE_DIR + text_file_name, \"r\", encoding=\"shift_jis\")\n",
    "\n",
    "        # 関数 get_data にファイル(オブジェクト)を渡す\n",
    "        get_data(text_file)\n",
    "\n",
    "        # テキストファイルを閉じる\n",
    "        text_file.close()\n",
    "\n",
    "print(CSV_FILE_DIR + CSV_FILE_NAME + \" を作成しました\")\n",
    "\n",
    "# 終了合図\n",
    "print(\"作業を終了しました\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
